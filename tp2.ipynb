{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP 2 - Inferencia y Estimacion\n",
    "\n",
    "Antonio Santiago Tepsich - Maximo Gubitosi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracción de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leer_archivo_csv(archivo_csv):\n",
    "    # Lista para almacenar los datos del archivo\n",
    "    altosGp1 = []\n",
    "    anchosGp1 = []\n",
    "    altosGp2 = []\n",
    "    anchosGp2 = []\n",
    "    gp1=[]\n",
    "    gp2=[]\n",
    "\n",
    "    try:\n",
    "        with open(archivo_csv, 'r', newline='') as csv_file:\n",
    "            csv_reader = csv.reader(csv_file)\n",
    "            next(csv_reader)\n",
    "\n",
    "            # Leer los datos del archivo\n",
    "            for row in csv_reader:\n",
    "                # Si la primera columna tiene valores numéricos, la segunda cadenas y la tercera flotantes\n",
    "                if(row[0] == '' or row[1] == '' or row[2] == ''):\n",
    "                    continue\n",
    "                if(row[0]==\"1\"):\n",
    "                    largo = int(row[1])\n",
    "                    alto = int(row[2])\n",
    "                    altosGp1.append(largo)\n",
    "                    anchosGp1.append(alto)\n",
    "                else:\n",
    "                    largo = int(row[1])\n",
    "                    alto = int(row[2])\n",
    "                    altosGp2.append(largo)\n",
    "                    anchosGp2.append(alto)\n",
    "            \n",
    "            gp1.append(altosGp1)\n",
    "            gp1.append(anchosGp1)\n",
    "            gp2.append(altosGp2)\n",
    "            gp2.append(anchosGp2)\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        print(f\"El archivo '{archivo_csv}' no fue encontrado.\")\n",
    "        return None\n",
    "\n",
    "    return gp1,gp2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entropía"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " En el contexto de la teoría de la información, la entropía mide la cantidad de información que se espera obtener de una nueva muestra de datos.\n",
    "\n",
    " $$ H(p) = -\\sum_{i} p_i \\log_2(p_i) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropia(p):\n",
    "    for i in range(len(p)):\n",
    "        if(p[i]==0):\n",
    "            p[i]=1\n",
    "    return -np.sum(p*np.log2(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grupo 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropia largo gp1:  1.7206031643621587\n",
      "Entropia alto gp1:  1.8415549118707901\n"
     ]
    }
   ],
   "source": [
    "gp1,gp2 = leer_archivo_csv('Todo.csv')\n",
    "\n",
    "matriz1 = np.histogram2d(gp1[0],gp1[1],bins=5)\n",
    "\n",
    "matriz1 = matriz1[0]/np.sum(matriz1[0])\n",
    "\n",
    "marginal_largo_gp1 = np.sum(matriz1,axis=1)\n",
    "marginal_ancho_gp1 = np.sum(matriz1,axis=0)\n",
    "\n",
    "# --------Calculo probabilidad del largo de gp1---------------- \n",
    "print(\"Entropia largo gp1: \",entropia(marginal_largo_gp1))\n",
    "\n",
    "# --------Calculo probabilidad del ancho de gp1----------------\n",
    "print(\"Entropia alto gp1: \",entropia(marginal_ancho_gp1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grupo 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropia largo gp2:  1.728481135079078\n",
      "Entropia alto gp2:  1.7906927146926772\n"
     ]
    }
   ],
   "source": [
    "gp1,gp2 = leer_archivo_csv('Todo.csv')\n",
    "\n",
    "matriz2 = np.histogram2d(gp2[0],gp2[1],bins=5)\n",
    "matriz2 = matriz2[0]/np.sum(matriz2[0])\n",
    "\n",
    "\n",
    "marginal_largo_gp2 = np.sum(matriz2,axis=1)\n",
    "marginal_ancho_gp2 = np.sum(matriz2,axis=0)\n",
    "\n",
    "# --------Calculo probabilidad del largo de gp2----------------\n",
    "print(\"Entropia largo gp2: \",entropia(marginal_largo_gp2))\n",
    "\n",
    "# --------Calculo probabilidad del ancho de gp2----------------\n",
    "print(\"Entropia alto gp2: \",entropia(marginal_ancho_gp2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusión\n",
    "\n",
    "Estos valores representan la cantidad de información (o incertidumbre) en las mediciones de las hojas. Al comparar las entropías de gp1 y gp2, podemos observar que las mediciones de gp1 presentan una mayor incertidumbre (o desorden) en comparación con las de gp2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entropía Condicional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La entropía condicional mide la incertidumbre promedio de una variable aleatoria X dado que el valor de otra variable aleatoria Y es conocido. Se utiliza para entender la cantidad de información que queda por conocer acerca de X después de observar Y.\n",
    "\n",
    "$$ H(X|Y) = \\sum_{y \\in Y} p(y) \\sum_{x \\in X} p(x|y) \\log_2 \\left(\\frac{1}{p(x|y)}\\right) $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conditonal_entropy(x, y, bins):\n",
    "    if len(x)<len(y):\n",
    "        #elegir randoms de y\n",
    "        y = np.random.choice(y, len(x))\n",
    "    elif len(y)<len(x):\n",
    "        #elegir randoms de x\n",
    "        x = np.random.choice(x, len(y))\n",
    "\n",
    "    \n",
    "    hist_2d, x_edges, y_edges = np.histogram2d(x, y, bins=bins)    \n",
    "    hist_2d = hist_2d/np.sum(hist_2d) #Matriz de probabilidades\n",
    "\n",
    "    conditonal_entropy = 0\n",
    "    for i in range (len(x_edges)-1):\n",
    "        for j in range (len(y_edges)-1):\n",
    "            if hist_2d[i,j] != 0:\n",
    "                conditonal_entropy -= hist_2d[i,j]*np.log2(hist_2d[i,j]/hist_2d[i].sum())\n",
    "\n",
    "    return conditonal_entropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H(A1/L1):  1.3115433811024402\n",
      "H(A2/L2):  1.1251274508998534\n",
      "H(A1/A2):  1.744401306971017\n",
      "H(L1/L2):  1.5389123759431875\n"
     ]
    }
   ],
   "source": [
    "gp1,gp2 = leer_archivo_csv('Todo.csv')\n",
    "\n",
    "# --------Calculo la entropia condicional de A1 dado L1----------------\n",
    "print(\"H(A1/L1): \",conditonal_entropy(gp1[0], gp1[1], 5))\n",
    "\n",
    "# --------Calculo la entropia condicional de A2 dado L2----------------\n",
    "print(\"H(A2/L2): \",conditonal_entropy(gp2[0], gp2[1], 5))\n",
    "\n",
    "# --------Calculo la entropia condicional de L1 dado A1----------------\n",
    "print(\"H(A1/A2): \",conditonal_entropy(gp2[1], gp1[1], 5))\n",
    "\n",
    "# --------Calculo la entropia condicional de L2 dado A2----------------\n",
    "print(\"H(L1/L2): \",conditonal_entropy(gp2[0], gp1[0], 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusión\n",
    "\n",
    "Estas medidas nos proporcionan información sobre cómo el conocimiento de una de las variables (como el largo de una hoja) puede influir en la incertidumbre de otra variable (como el alto de la misma hoja o de otra hoja)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Información Mutua"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La información mutua entre dos variables aleatorias X e Y mide la cantidad de información que se puede obtener sobre una variable al observar la otra.\n",
    "\n",
    "$$\n",
    "I(X;Y) = H(X) - H(X|Y) = \\sum_{x \\in X, y \\in Y} p(x,y) \\log_2 \\left(\\frac{p(x,y)}{p(x)p(y)}\\right)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I(A1/L1):  0.4090597832597185\n",
      "I(A2/L2):  0.7164274609709367\n"
     ]
    }
   ],
   "source": [
    "gp1,gp2 = leer_archivo_csv('Todo.csv')\n",
    "\n",
    "# I(A/L) = H(A) - H(A/L)\n",
    "\n",
    "\n",
    "matriz1 = np.histogram2d(gp1[0],gp1[1],bins=5)\n",
    "\n",
    "matriz1 = matriz1[0]/np.sum(matriz1[0])\n",
    "\n",
    "\n",
    "#--------Calculon probabilidad del ancho de gp1---------------- \n",
    "marginal_largo_gp1 = np.sum(matriz1,axis=1)\n",
    "\n",
    "#--------Calculon probabilidad del alto de gp2----------------\n",
    "marginal_ancho_gp1 = np.sum(matriz1,axis=0)\n",
    "\n",
    "# ----------Informacion Mutua entre A1 y L1----------------\n",
    "print(\"I(A1/L1): \",entropia(marginal_largo_gp1)-conditonal_entropy(gp1[0], gp1[1], 5))\n",
    "\n",
    "# ----------Informacion Mutua entre A2 y L2----------------\n",
    "print(\"I(A2/L2): \",entropia(marginal_ancho_gp1)-conditonal_entropy(gp2[0], gp2[1], 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusión\n",
    "\n",
    "Para ambos grupos hay una cantidad significativa de información compartida entre el largo y ancho de las hojas en cada grupo especifico. Algo que nos resulta interesante, ya que si conocemos el valor de uno de estos atributos, podemos hacer una predicción razonablemente precisa sobre el otro atributo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distancia Kullback–Leibler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La divergencia de Kullback-Leibler es una medida de cuán diferente es una distribución probabilística p de otra distribución q.\n",
    "\n",
    "$$D(p(x,y) || q(x,y)) = \\sum_{x} \\sum_{y} p(x,y) \\log \\left( \\frac{p(x,y)}{q(x,y)} \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------Distancia de Kullback-Leibler entre gp1 y gp2----------------\n",
    "def kullback_leibler(p, q):\n",
    "    if len(p[0]) > len(q[0]):\n",
    "        #elegir randoms de q\n",
    "        q[0] = np.random.choice(q[0], len(p[0]))\n",
    "    elif len(q[0]) > len(p[0]):\n",
    "        #elegir randoms de p\n",
    "        p[0] = np.random.choice(p[0], len(q[0]))\n",
    "\n",
    "    if len(p[1]) > len(q[1]):\n",
    "        #elegir randoms de q\n",
    "        q[1] = np.random.choice(q[1], len(p[1]))\n",
    "    elif len(q[1]) > len(p[1]):\n",
    "        #elegir randoms de p\n",
    "        p[1] = np.random.choice(p[1], len(q[1]))\n",
    "\n",
    "    p_hist_2d, x_edges, y_edges = np.histogram2d(p[0], p[1], bins=5)\n",
    "    p_hist_2d = p_hist_2d/np.sum(p_hist_2d) #Matriz de probabilidades\n",
    "\n",
    "    q_hist_2d, x_edges, y_edges = np.histogram2d(q[0], q[1], bins=5)\n",
    "    q_hist_2d = q_hist_2d/np.sum(q_hist_2d) #Matriz de probabilidades\n",
    "\n",
    "    suma=0\n",
    "    for i in range(len(x_edges)-1):\n",
    "        for j in range(len(y_edges)-1):\n",
    "            p1=p_hist_2d[i][j]\n",
    "            q1=q_hist_2d[i][j]\n",
    "            if q1!=0 and p1!=0:\n",
    "                suma+=p1*np.log2(p1/q1)\n",
    "    return suma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D(gp1||gp2):  0.9325444291891447\n"
     ]
    }
   ],
   "source": [
    "gp1,gp2 = leer_archivo_csv('Todo.csv')\n",
    "\n",
    "print(\"D(gp1||gp2): \", kullback_leibler(gp1, gp2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusión\n",
    "\n",
    "EL resultado obtenido sugiere que existe una diferencia significativa en la distribución de las medidas de ancho y largo entre los dos grupos de hojas. Específicamente, este valor indica cuánto difieren las probabilidades del grupo gp1 respecto a las del grupo gp2 en términos de ancho y largo. Al ser un valor mayor a cero, esto sugiere que las distribuciones no son idénticas, y que gp1 se desvía de gp2 en una medida de 0.9131 en términos de su contenido de información."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
